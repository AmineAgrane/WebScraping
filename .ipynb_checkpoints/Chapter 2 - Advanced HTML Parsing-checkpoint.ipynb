{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Don’t Always Need a Hammer\n",
    "\n",
    "It can be tempting, when faced with a lot of tags, to dive right in and use multiline statements to try to extract your information. However, keep in mind that layering the techniques used in this section without consideration can lead to code\n",
    "that is difficult to debug, fragile, or both.\n",
    "\n",
    "\n",
    "For example, the following line : \n",
    "`bs.find_all('table')[4].find_all('tr')[2].find('td').find_all('div')[1].find('a')` doesn't looks so great. So what are your options ?\n",
    "\n",
    " \n",
    "   * Look for a “Print This Page” link, or perhaps a mobile version of the site that has better-formatted HTML\n",
    "   * Look for the information hidden in a JavaScript file.\n",
    "   * The information might be available in the URL of the page itself.\n",
    "\n",
    "\n",
    "It’s important not to just start digging and write yourself into a hole that you might not be able to get out of. Take a deep breath and think of alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find() and find_all() with BeautifulSoup\n",
    "\n",
    "BeautifulSoup’s `find()` and `find_all()` are the two functions we'll use the most. The two functions are extremely similar, as evidenced by their definitions in the BeautifulSoup documentation:\n",
    "\n",
    "`\n",
    "find_all(tag, attributes, recursive, text, limit, keywords)\n",
    "find(tag, attributes, recursive, text, keywords)\n",
    "`\n",
    "\n",
    "95% of the time we will need to use only the first two arguments: **`tag`** and **`attributes`**; However, let’s take a look at all the arguments in greater detail.\n",
    "\n",
    "   * **`tag`** : The tag argument takes a string name of a tag or a Python list of string tag names. For example, the following returns a list of all the header tags in a document:\n",
    "   `bs.find_all(['h1','h2','h3','h4','h5','h6'])`\n",
    "   \n",
    "   \n",
    "   * **`attributes`** : The attributes argument takes a Python dictionary of attributes and matches tags that contain ANY of those attributes. For example, the following function would return both the green and red span tags in the HTML document:\n",
    "   `bs.find_all('span', {'class':{'green', 'red'}})`\n",
    "   \n",
    "   \n",
    "   * **`recursive`** : If recursive is set to True, the find_all function looks into children nodes. If it is False, it will look only at the top-level tags in your document. By default, find_all works recursively (recursive is set to True);\n",
    "   \n",
    "   \n",
    "   * **`text`** : The text argument is unusual in that it matches based on the text content of the tags, rather than its properties. For instance, if you want to find all the tags that contains the string “the prince”, we could use : \n",
    "   `bs.find_all(text='the prince')`\n",
    "   \n",
    "   \n",
    "   * **`keywords`** : The keyword argument allows you to select tags that contain a particular attribute or set of attributes. However, it is technically redundant as a BeautifulSoup feature. For instance, the following two lines are identical:\n",
    "   `bs.find_all(id='text')\n",
    "bs.find_all('', {'id':'text'})`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select tags based on their attributes values\n",
    "\n",
    "Let’s create an example web scraper that scrapes the page located at http://www.pythonscraping.com/pages/warandpeace.html. On this page, the lines spoken by characters in the story are in red, whereas the\n",
    "names of characters are in green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Grab the entire page and create a BeautifulSoup object\n",
    "html = urlopen('http://www.pythonscraping.com/pages/warandpeace.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the function **`find_all`** of BeautifulSoup with following format `bs.find_all(tagName, tagAttributes)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, Prince, so Genoa and Lucca are now just family estates of the\n",
      "Buonapartes. But I warn you, if you don't tell me that this means war,\n",
      "if you still try to defend the infamies and horrors perpetrated by\n",
      "that Antichrist- I really believe he is Antichrist- I will have\n",
      "nothing more to do with you and you are no longer my friend, no longer\n",
      "my 'faithful slave,' as you call yourself! But how do you do? I see\n",
      "I have frightened you- sit down and tell me all the news. \n",
      "\n",
      "If you have nothing better to do, Count [or Prince], and if the\n",
      "prospect of spending an evening with a poor invalid is not too\n",
      "terrible, I shall be very charmed to see you tonight between 7 and 10-\n",
      "Annette Scherer. \n",
      "\n",
      "Heavens! what a virulent attack! \n",
      "\n",
      "First of all, dear friend, tell me how you are. Set your friend's\n",
      "mind at rest, \n",
      "\n",
      "Can one be well while suffering morally? Can one be calm in times\n",
      "like these if one has any feeling? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the find_all function to extract a Python list of span tag with red class\n",
    "tags = bs.find_all('span', {'class':'red'})\n",
    "\n",
    "for tag in tags[:5]:\n",
    "    print(tag.get_text(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating Trees\n",
    "   * We use tree navigation to find a tag based on its location in a document We can navigate up, across, and diagonally through HTML trees. In the BeautifulSoup library, there is a distinction between children and descendants: children are always exactly one tag below a parent, whereas descendants can be at any level in the tree below a parent. All children are descendants, but not all descendants are children.\n",
    "   \n",
    "   \n",
    "   * BeautifulSoup functions always deal with the descendants of the current tag selected. \n",
    "     * `bs.body.h1` selects the first h1 tag that is a descendant of the body tag. It will not find tags located outside the body.\n",
    "     * `bs.div.find_all('img')` will find the first div tag in the document, and then retrieve a list of all img tags that are descendants of that div tag.\n",
    "     \n",
    "     \n",
    " The **`nextSibling`** attribute is used to return the direct next tag of the specified tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page3.html')\n",
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with children and other descendants\n",
    "\n",
    "The attribute **`chlidren`** returns a list of all the children of the specified tag. The attribute **`descendants`** returns a list of all the descendants of the specified tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list_iterator of all the children of the 'table' tag.\n",
    "children = bs.find('table',{'id':'giftList'}).children\n",
    "\n",
    "# generator of all the descendants of the 'table' tag.\n",
    "descendants = bs.find('table',{'id':'giftList'}).descendants\n",
    "\n",
    "#for c in children: print(c)\n",
    "#for d in descendants: print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with siblings\n",
    "\n",
    "The output of this code is to print all rows of products from the product table, except for the first title row. Anytime you get siblings of an object, the object itself will not be included in the list because objects cannot be siblings with themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator of all the siblings of the fir 'tr' tag inside the 'table' tag.\n",
    "siblings = bs.find('table',{'id':'giftList'}).tr.next_siblings\n",
    "#for s in siblings: print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with parents\n",
    "\n",
    "You can find yourself in odd situations that require BeautifulSoup’s parent-finding functions, .parent and .parents. For example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$15.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Insepect the HTML content to understand how the \"parent\" method works.\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page3.html')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "print(bs.find('img', {'src':'../img/gifts/img1.jpg'}).parent.previous_sibling.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WebScraping",
   "language": "python",
   "name": "webscraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
